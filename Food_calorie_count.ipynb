{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_7fq9NmAXO7",
        "outputId": "b7f04ed8-0f40-4f5d-a6cf-c234ea22a973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/dansbecker/food-101?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.38G/9.38G [07:05<00:00, 23.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/dansbecker/food-101/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"dansbecker/food-101\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(path):\n",
        "    if 'images' in dirs and '__MACOSX' not in root:\n",
        "        dataset_path = os.path.join(root, 'images')\n",
        "        print(\"âœ… Actual dataset images folder:\", dataset_path)\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No1z6D5TeBSo",
        "outputId": "48c004a0-9c1b-4f1d-a0e9-8359f2f6a6c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Actual dataset images folder: /root/.cache/kagglehub/datasets/dansbecker/food-101/versions/1/food-101/food-101/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/root/.cache/kagglehub/datasets/dansbecker/food-101/versions/1/food-101/food-101/images\"\n"
      ],
      "metadata": {
        "id": "M-PGACGwe5Np"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load pre-trained ResNet18 and modify final layer\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)  # 10 classes\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG94uOPde-Ef",
        "outputId": "aaef1e14-8617-4671-b9b3-b6975b13d3c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 60.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n"
      ],
      "metadata": {
        "id": "xbkfXWsRfBZM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/root/.cache/kagglehub/datasets/dansbecker/food-101/versions/1/food-101/food-101/images\"\n",
        "\n",
        "# âœ… Filter to only directories\n",
        "all_classes = sorted([\n",
        "    d for d in os.listdir(dataset_path)\n",
        "    if os.path.isdir(os.path.join(dataset_path, d))\n",
        "])\n",
        "\n",
        "selected_classes = all_classes[:10]  # Pick first 10\n",
        "image_paths = []\n",
        "\n",
        "for cls in selected_classes:\n",
        "    class_dir = os.path.join(dataset_path, cls)\n",
        "    images = [os.path.join(cls, img) for img in os.listdir(class_dir)]\n",
        "    image_paths.extend(images)\n",
        "\n",
        "random.shuffle(image_paths)\n",
        "\n",
        "split_idx = int(0.8 * len(image_paths))\n",
        "train_list = image_paths[:split_idx]\n",
        "test_list = image_paths[split_idx:]\n",
        "\n",
        "print(f\"âœ… Reduced dataset to {len(selected_classes)} classes.\")\n",
        "print(\"âœ… Train/Test split done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NT9xg5SfE7b",
        "outputId": "5204c1ed-d143-4ca9-d1be-f68325577634"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Reduced dataset to 10 classes.\n",
            "âœ… Train/Test split done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchvision import transforms\n",
        "\n",
        "# Label encode the class names\n",
        "all_labels = [img_path.split('/')[0] for img_path in train_list + test_list]\n",
        "le = LabelEncoder()\n",
        "le.fit(all_labels)\n",
        "\n",
        "# Define image transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Custom Dataset\n",
        "class Food101Dataset(Dataset):\n",
        "    def __init__(self, image_list, root_dir, label_encoder, transform=None):\n",
        "        self.image_list = image_list\n",
        "        self.root_dir = root_dir\n",
        "        self.le = label_encoder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_list[idx]\n",
        "        full_path = os.path.join(self.root_dir, img_path)\n",
        "        image = Image.open(full_path).convert(\"RGB\")\n",
        "\n",
        "        label_str = img_path.split('/')[0]\n",
        "        label = self.le.transform([label_str])[0]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Initialize datasets\n",
        "train_dataset = Food101Dataset(train_list, dataset_path, le, transform)\n",
        "test_dataset = Food101Dataset(test_list, dataset_path, le, transform)\n",
        "\n",
        "# Create data loaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"âœ… Data loaders ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-_0j1AgfW9H",
        "outputId": "9006a5bb-a8c8-4ff1-b9e5-0eb622b9a3df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data loaders ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load ResNet18 with pretrained weights\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# Replace the final fully connected layer to match number of classes\n",
        "num_classes = len(le.classes_)  # Should be 10\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Move model to GPU (if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"âœ… Model ready on device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQQnUni1flma",
        "outputId": "53643ad3-4e1c-4427-f0e9-4bd03c819e2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model ready on device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "Xkw2S-39fsOy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    print(f\"âœ… Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN3OlfsRfu0g",
        "outputId": "587ebd63-37cd-4fa3-8c86-51490811c63b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch [1/3], Loss: 0.1143, Accuracy: 96.29%\n",
            "âœ… Epoch [2/3], Loss: 0.1005, Accuracy: 96.69%\n",
            "âœ… Epoch [3/3], Loss: 0.0357, Accuracy: 98.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"âœ… Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1gh9jggfzUn",
        "outputId": "bad966bb-a716-477f-c037-baec15a0ab63"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Test Accuracy: 74.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "selected_classes = le.classes_.tolist()\n",
        "\n",
        "print(\"Selected 10 food classes from LabelEncoder:\")\n",
        "for i, cls in enumerate(selected_classes, 1):\n",
        "    print(f\"{i}. {cls}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6ldiOeJmD0o",
        "outputId": "5fb662ae-4bdd-478d-b214-1abb41a4f391"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected 10 food classes from LabelEncoder:\n",
            "1. apple_pie\n",
            "2. baby_back_ribs\n",
            "3. baklava\n",
            "4. beef_carpaccio\n",
            "5. beef_tartare\n",
            "6. beet_salad\n",
            "7. beignets\n",
            "8. bibimbap\n",
            "9. bread_pudding\n",
            "10. breakfast_burrito\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calorie_dict = {\n",
        "    \"apple_pie\": 296,\n",
        "    \"baby_back_ribs\": 320,\n",
        "    \"baklava\": 290,\n",
        "    \"beef_carpaccio\": 180,\n",
        "    \"beef_tartare\": 250,\n",
        "    \"beet_salad\": 150,\n",
        "    \"beignets\": 220,\n",
        "    \"bibimbap\": 500,\n",
        "    \"bread_pudding\": 300,\n",
        "    \"breakfast_burrito\": 450\n",
        "}\n"
      ],
      "metadata": {
        "id": "CrobVIa-gtzc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Same transform used during training\n",
        "predict_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ],
      "metadata": {
        "id": "HWNpHt_4iu6s"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "def predict_image_with_calories(image_path, model, label_encoder, calorie_info):\n",
        "    model.eval()\n",
        "\n",
        "    # Load image and preprocess\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_tensor = predict_transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "\n",
        "    predicted_label = label_encoder.inverse_transform([predicted.cpu().item()])[0]\n",
        "\n",
        "    # Get calories from dict\n",
        "    calories = calorie_info.get(predicted_label, \"N/A\")\n",
        "\n",
        "    return predicted_label, calories\n"
      ],
      "metadata": {
        "id": "s3flrpVgixm4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Find a real image path from one of the selected classes\n",
        "for cls in selected_classes:\n",
        "    class_dir = os.path.join(dataset_path, cls)\n",
        "    image_files = [f for f in os.listdir(class_dir) if f.endswith('.jpg')]\n",
        "    if image_files:\n",
        "        sample_image_path = os.path.join(class_dir, image_files[0])\n",
        "        print(\"âœ… Sample image found:\", sample_image_path)\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTAJgcY_i4JZ",
        "outputId": "76005a6f-ffc4-4b0d-8378-557c37cc7646"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Sample image found: /root/.cache/kagglehub/datasets/dansbecker/food-101/versions/1/food-101/food-101/images/apple_pie/2536578.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the sample path we found\n",
        "sample_image_path = \"/root/.cache/kagglehub/datasets/dansbecker/food-101/versions/1/food-101/food-101/images/apple_pie/2536578.jpg\"\n",
        "\n",
        "# Predict\n",
        "predicted_class, calories = predict_image_with_calories(sample_image_path, model, le, calorie_dict)\n",
        "\n",
        "# Output results\n",
        "print(f\"ðŸ½ï¸ Predicted class: {predicted_class}\")\n",
        "print(f\"ðŸ”¥ Calories per serving: {calories} kcal\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSh9Jk2qi7RD",
        "outputId": "1422c089-a5ae-4d71-bfaf-a868a0add024"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ½ï¸ Predicted class: apple_pie\n",
            "ðŸ”¥ Calories per serving: 296 kcal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3AMaJjAajx7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}